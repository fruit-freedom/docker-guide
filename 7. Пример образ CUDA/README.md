Использование CUDA приложений в докере
--------------------------------------

Даннй пример позволит рассказать об особенностях работы с технологией `CUDA` используя докер контейнеры.

Для работы с CUDA из контейнера на хостовом устройство необходимо иметь две вещи:
- Актуальный `nvidia` драйвер с поддержкой `CUDA`
- `nvidia` драйвер для докера

> Обратите внимание что для работы с `CUDA` из контейнера нет необходимости
> ставить `CUDA` на хост, что значительно упрощает деплой приложения и позволяет использовать
> необходимую Вам версию библиотеки.

Установку драйверов для видеокарты мы пропустим.

Установка драйвер для докера подробно описана на
[официальном сайте](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) `nvidia`.

> Обязательно после установки драйвера перезапустите докер демона `sudo systemctl restart docker`.


Для проверки корректности установки можно использовать следующую команду:

```
docker run --rm --gpus all ubuntu:22.04 nvidia-smi
```

которая запускает образ убунты и выполняет в нем `nvidia-smi` (утилита для отображения информации о доступных GPU).
`nvidia-smi` станавливается вместе с драйверами для видеокарты и пробрасывается в запущенный контейнер вместе со всеми
драйверами благодаря флагу `--gpus all`.
В случае успеха на экран должна быть выведена информация о количестве GPU, их загруженности, а также версии драйве и поддреживаемой
версии `CUDA`.


В качестве тестого примера был выбран пример сложения двух векторов. Программа приведена в файле `main.cu`.
Сборка программы осуществлялась через утилиту `cmake`

> Мы рекомендуем использовать систему сборки `cmake` как простой и популярный метод сборки кросплатформенных программ.
> Рекомендуем к прочтению [Cmake CUDA guide](https://developer.nvidia.com/blog/building-cuda-applications-cmake/).


Используя следующую команду соберем образ 
```
docker build -t cuda_vector_add .
```
а затем запустим его, передав специальный флаг `--gpus`, который регулирует количество девайсов
с которыми может взаимодействовать контейнер.

```
docker run --rm --gpus all cuda_vector_add
```

Для сборки образа мы импользовали готовые официальные образы `nvidia/cuda:12.0.0-devel-ubuntu22.04` и `nvidia/cuda:12.0.0-runtime-ubuntu22.04`.
Полный список достпных образов доступен [здесь](https://hub.docker.com/r/nvidia/cuda/tags). При выборе образа указывается опреционная система
которая будет использована в контейнере, версия `CUDA`, а также тип пакета (`devel` или `runtime`). Тип пакета указывает на то, содержит ли
образ необходимые для сборки и отладки инструмены (компилятор, заголовочные фалы и тд).

> Мы рекомендуем использовать официальные образы, так как это позволяет избежать многочисленные проблемы с версионностью.


